{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "19c41f88",
      "metadata": {
        "id": "19c41f88"
      },
      "source": [
        "# Homework: Documenting Your Code + Testing Your Code\n",
        "\n",
        "## Problem 1 - Write docstrings\n",
        "\n",
        "The following functions are missing docstrings. Write Google-style docstrings for each function, including `Args`, `Returns`, and `Raises` sections where appropriate. Make sure to document default values and explain what each parameter means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cacdf2c",
      "metadata": {
        "id": "2cacdf2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(data, method=\"zscore\"):\n",
        "    \"\"\"Normalize an array of numerical data.\n",
        "\n",
        "    Normalization rescales the data according to the specified method.\n",
        "\n",
        "    Args:\n",
        "        data (np.ndarray): Input array of numerical values to normalize.\n",
        "        method (str, optional): Normalization method to use.\n",
        "            Supported values are:\n",
        "            - \"zscore\": Standardize data to mean 0 and standard deviation 1.\n",
        "            - \"minmax\": Scale data to the range [0, 1].\n",
        "            Defaults to \"zscore\".\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A new array containing the normalized data.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If an unsupported normalization method is specified.\n",
        "    \"\"\"\n",
        "    if method == \"zscore\":\n",
        "        return (data - np.mean(data)) / np.std(data)\n",
        "    elif method == \"minmax\":\n",
        "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "\n",
        "def weighted_mean(values, weights=None):\n",
        "    \"\"\"Compute the weighted mean of a set of values.\n",
        "\n",
        "    If no weights are provided, this function returns the arithmetic mean.\n",
        "\n",
        "    Args:\n",
        "        values (np.ndarray): Array of numerical values.\n",
        "        weights (np.ndarray, optional): Array of weights corresponding to\n",
        "            each value. Must have the same length as `values`.\n",
        "            Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: The weighted mean of the values.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If `weights` is provided and its length does not match\n",
        "            the length of `values`.\n",
        "    \"\"\"\n",
        "    if weights is None:\n",
        "        return np.mean(values)\n",
        "    if len(values) != len(weights):\n",
        "        raise ValueError(\"values and weights must have the same length\")\n",
        "    return np.sum(values * weights) / np.sum(weights)\n",
        "\n",
        "\n",
        "def remove_outliers(data, threshold=3.0):\n",
        "    \"\"\"Remove outliers from data using a z-score threshold.\n",
        "\n",
        "    Data points are considered outliers if their absolute deviation from\n",
        "    the mean exceeds `threshold` standard deviations.\n",
        "\n",
        "    Args:\n",
        "        data (np.ndarray): One-dimensional array of numerical data.\n",
        "        threshold (float, optional): Number of standard deviations from\n",
        "            the mean beyond which a point is considered an outlier.\n",
        "            Defaults to 3.0.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A filtered array containing only non-outlier values.\n",
        "    \"\"\"\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    mask = np.abs(data - mean) <= threshold * std\n",
        "    return data[mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16fb210",
      "metadata": {
        "id": "f16fb210"
      },
      "source": [
        "## Problem 2 - Add type hints\n",
        "\n",
        "The following functions have incomplete or missing type hints. Add appropriate type hints for all parameters and return values. Use `|` syntax for union types where a parameter can accept multiple types or return `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e458a748",
      "metadata": {
        "id": "e458a748"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def clip_values(arr: np.ndarray,\n",
        "                lower: int | float,\n",
        "                upper: int | float\n",
        "                ) -> np.ndarray :\n",
        "    \"\"\"Clip array values to be within [lower, upper] range.\"\"\"\n",
        "    return np.clip(arr, lower, upper)\n",
        "\n",
        "\n",
        "def find_peaks(data: list[float],\n",
        "               min_height: float | None=None\n",
        "               ) -> list[int] | None:\n",
        "    \"\"\"Find indices where values are local maxima above min_height.\n",
        "\n",
        "    Returns None if no peaks are found.\n",
        "    \"\"\"\n",
        "    peaks = []\n",
        "    for i in range(1, len(data) - 1):\n",
        "        if data[i] > data[i - 1] and data[i] > data[i + 1]:\n",
        "            if min_height is None or data[i] >= min_height:\n",
        "                peaks.append(i)\n",
        "    if len(peaks) == 0:\n",
        "        return None\n",
        "    return peaks\n",
        "\n",
        "\n",
        "def summarize(data: np.ndarray,\n",
        "              stats: list[str]\n",
        "              ) dict[str, float]:\n",
        "    \"\"\"Calculate summary statistics for data.\n",
        "\n",
        "    Args:\n",
        "        data: Input array of numeric values.\n",
        "        stats: List of statistic names to compute.\n",
        "            Valid options: \"mean\", \"median\", \"std\", \"min\", \"max\"\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping statistic names to computed values.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    for stat in stats:\n",
        "        if stat == \"mean\": result[stat] = np.mean(data)\n",
        "        elif stat == \"median\":\n",
        "            result[stat] = np.median(data)\n",
        "        elif stat == \"std\":\n",
        "            result[stat] = np.std(data)\n",
        "        elif stat == \"min\":\n",
        "            result[stat] = np.min(data)\n",
        "        elif stat == \"max\":\n",
        "            result[stat] = np.max(data)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66a6400",
      "metadata": {
        "id": "b66a6400"
      },
      "source": [
        "## Problem 3: Identifying Test Types\n",
        "\n",
        "For each scenario below, identify whether the test being described is a **unit test**, **integration test**, or **regression test**. Briefly explain your reasoning.\n",
        "\n",
        "**(a)** You write a test that verifies `calculate_variance()` returns 0 for the input `[3.0, 3.0, 3.0]`.\n",
        "\n",
        "**Unit test**. This targets a single function and checks an isolated behavior for a specific input, with no other components involved.\n",
        "\n",
        "**(b)** After discovering that `fit_model()` crashes when given a dataset with a single row, you fix the bug and add a test with a one-row input.\n",
        "\n",
        "**Regression test**. This test is added after discovering a bug, and ensures that the bug does not reappear in the future.\n",
        "\n",
        "**(c)** You write a test that loads data from a CSV file, passes it through `clean_data()`, fits a model with `fit_linear_regression()`, and verifies the model's R-squared value is within an expected range.\n",
        "\n",
        "**Integration test**. This test verifies that the file is loaded, data is cleaned, and model is fit correctly, checking that these components work together.\n",
        "\n",
        "**(d)** A user reports that `normalize()` returns incorrect values when all input values are negative. After fixing the issue, you add a test with input `[-5.0, -3.0, -1.0]`.\n",
        "\n",
        "**Regression test**. This test is once again added after discovering a bug, and ensures that the function no longer returns incorrect values.\n",
        "\n",
        "## Problem 4: Code Review - What's Wrong with These Tests?\n",
        "\n",
        "Review the following test code and identify at least **four** problems with the test design or implementation. Explain why each is problematic and suggest how to fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0f31e7",
      "metadata": {
        "id": "bb0f31e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def test_all_statistics():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "\n",
        "    # Test mean\n",
        "    assert np.mean(data) == 30\n",
        "\n",
        "    # Test median\n",
        "    assert np.median(data) == 30\n",
        "\n",
        "    # Test standard deviation\n",
        "    assert np.std(data) > 0\n",
        "\n",
        "    # Test min and max\n",
        "    assert np.min(data) == 10\n",
        "    assert np.max(data) == 50\n",
        "\n",
        "    # Test sum\n",
        "    assert np.sum(data) == 150\n",
        "\n",
        "def verify_variance_positive(arr):\n",
        "    var = np.var(arr)\n",
        "    assert var >= 0\n",
        "\n",
        "def test_correlation():\n",
        "    x = np.array([1.0, 2.0, 3.0])\n",
        "    y = np.array([2.0, 4.0, 6.0])\n",
        "    corr = np.corrcoef(x, y)[0, 1]\n",
        "    assert corr == 1.0\n",
        "\n",
        "results = []\n",
        "\n",
        "def test_append_result():\n",
        "    global results\n",
        "    results.append(42)\n",
        "    assert 42 in results\n",
        "\n",
        "def test_check_results():\n",
        "    assert len(results) == 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests recheck NumPy's built-in behavior and not actually testing the individual's code. In other words, the tests are meaningless.\n",
        "# To fix this, we need to test our own functions instead of NumPy's. For example,\n",
        "assert calculate_mean(data) == 30"
      ],
      "metadata": {
        "id": "EZQdfX6JmcDL"
      },
      "id": "EZQdfX6JmcDL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_all_statistics checks several statistics in one test, so if one fails, the rest are never executed.\n",
        "# A better way to test statistics is to create a function for each one. For example,\n",
        "def test_mean():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    assert np.mean(data) == 30\n",
        "def test_median():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    assert np.median(data) == 30"
      ],
      "metadata": {
        "id": "m78_tR46mcXk"
      },
      "id": "m78_tR46mcXk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify_variance_positive has inconsistent naming with the others.\n",
        "# We can make this a proper test by saying\n",
        "def test_variance_positive(arr)\n",
        "    assert np.var(arr) >= 0"
      ],
      "metadata": {
        "id": "GB-uvELemckY"
      },
      "id": "GB-uvELemckY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_append_result and test_check_results share the global `results`, so the tests ultimately depend on execution order.\n",
        "# To fix this, we need to use local variables rather than global:\n",
        "def test_append_result():\n",
        "    results = []\n",
        "    results.append(42)\n",
        "    assert results == [42]\n",
        "\n",
        "def test_check_results():\n",
        "    results = []\n",
        "    assert len(results) == 1"
      ],
      "metadata": {
        "id": "D1P20Wrymcxu"
      },
      "id": "D1P20Wrymcxu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3030fab2",
      "metadata": {
        "id": "3030fab2"
      },
      "source": [
        "## Problem 5: The Flaky Test\n",
        "\n",
        "Your colleague wrote the following test for a bootstrap confidence interval function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "235ca02a",
      "metadata": {
        "id": "235ca02a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def bootstrap_ci(data, confidence=0.95, n_bootstrap=1000):\n",
        "    \"\"\"Compute bootstrap confidence interval for the mean.\"\"\"\n",
        "    means = []\n",
        "    n = len(data)\n",
        "    for _ in range(n_bootstrap):\n",
        "        sample = np.random.choice(data, size=n, replace=True)\n",
        "        means.append(np.mean(sample))\n",
        "\n",
        "    alpha = 1 - confidence\n",
        "    lower = np.percentile(means, 100 * alpha / 2)\n",
        "    upper = np.percentile(means, 100 * (1 - alpha / 2))\n",
        "    return lower, upper\n",
        "\n",
        "def test_bootstrap_ci_contains_true_mean():\n",
        "    data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "    true_mean = 5.5\n",
        "    lower, upper = bootstrap_ci(data)\n",
        "    assert lower < true_mean < upper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860f28d3",
      "metadata": {
        "id": "860f28d3"
      },
      "source": [
        "**(a)** The test passes most of the time but occasionally fails. Explain why this test is \"flaky\" (non-deterministic).\n",
        "\n",
        "This test is non-deterministic because bootstrap_ci uses random resampling, with no random seed. We have a finite number of samples, 1000, so the estimated interval varies for each run.\n",
        "\n",
        "**(b)** Your colleague argues: \"The test is correct because a 95% confidence interval should contain the true mean 95% of the time, so occasional failures are expected.\" Is this a good argument for keeping the test as-is? Why or why not?\n",
        "\n",
        "Although this is a correct interpretation, it is a bad argument for keeping the test. The unit test we have here should be deterministic; if not, the test is untrustworthy since we cannot distinguish true bugs from random noise. In other words, we do not have a reproducible unit test, so it must be changed.\n",
        "\n",
        "**(c)** Rewrite the test to be deterministic and reliable while still meaningfully testing the `bootstrap_ci` function. Your solution should: ensure reproducible results and verify that the confidence interval has reasonable properties.\n",
        "\n",
        "Code below\n",
        "\n",
        "**(d)** Propose an alternative testing strategy that could verify the 95% coverage property without making the test flaky. You don't need to implement it, but describe the approach.\n",
        "\n",
        "To test the 95% coverage property, we could use a simulation-based test. First, we would have to fix a distribution, such as normal with a known mean. Then, we would repeat the following for a fixed number of simulations: generate dataset, compute 95% bootstrap confidence interval, record whether it contains the true mean. Finally, we would check if the empirical coverage is close to 0.95, within a tolerance of say Â±0.02."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def test_bootstrap_ci_properties():\n",
        "    \"\"\"\n",
        "    Test that bootstrap_ci is reproducible with a fixed random seed and\n",
        "    returns a valid confidence interval.\n",
        "    \"\"\"\n",
        "    np.random.seed(12345)\n",
        "\n",
        "    data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "    sample_mean = np.mean(data)\n",
        "\n",
        "    lower, upper = bootstrap_ci(data, confidence=0.95, n_bootstrap=5000)\n",
        "\n",
        "    # Interval should be ordered correctly\n",
        "    assert lower < upper\n",
        "\n",
        "    # Interval should contain the sample mean (much stronger and deterministic)\n",
        "    assert lower <= sample_mean <= upper\n",
        "\n",
        "    # Interval should have nonzero width\n",
        "    assert upper - lower > 0\n"
      ],
      "metadata": {
        "id": "mlgIaZEVmhwD"
      },
      "id": "mlgIaZEVmhwD",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_bootstrap_ci_properties()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "ykJM1XMOnLPX",
        "outputId": "edde125e-71b7-45fc-802e-125356d8aeb4"
      },
      "id": "ykJM1XMOnLPX",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bootstrap_ci' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-730940353.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_bootstrap_ci_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3453913512.py\u001b[0m in \u001b[0;36mtest_bootstrap_ci_properties\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msample_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_ci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Interval should be ordered correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bootstrap_ci' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}